{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標 :\n",
    "\n",
    "運用 Keras 模組建構CNN, 了解 CNN 的架構\n",
    "\n",
    "\n",
    "## 範例重點\n",
    "\n",
    "CNN 模型必要的: Convolution, Pooling, Flatten, Fully connection, Output, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "#導入相關模組\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "#確認keras 版本\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 09:30:59.366010 4406941120 deprecation_wrapper.py:119] From /Users/johnsonhuang/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0801 09:30:59.384871 4406941120 deprecation_wrapper.py:119] From /Users/johnsonhuang/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0801 09:30:59.387706 4406941120 deprecation_wrapper.py:119] From /Users/johnsonhuang/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0801 09:30:59.405905 4406941120 deprecation_wrapper.py:119] From /Users/johnsonhuang/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 25)        7225      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               62600     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 71,155\n",
      "Trainable params: 71,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#建立一個序列模型\n",
    "model = models.Sequential()\n",
    "\n",
    "#建立一個卷績層, 32 個內核, 內核大小 3x3, \n",
    "#輸入影像大小 28x28x1\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "#新增一池化層, 採用maxpooling\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "#建立第二個卷績層, 池化層, \n",
    "#請注意, 不需要再輸入 input_shape\n",
    "model.add(layers.Conv2D(25, (3, 3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "#新增平坦層\n",
    "model.add(Flatten())\n",
    "\n",
    "#建立一個全連接層\n",
    "model.add(Dense(units=100))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#建立一個輸出層, 並採用softmax\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#輸出模型的堆疊\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標:\n",
    "\n",
    "運用 Keras 模組建構CNN, 了解 CNN 的架構\n",
    "\n",
    "\n",
    "## 作業重點\n",
    "\n",
    "(1)嘗試比對 Dense 與 layers.Conv2D 架構NN 的差異\n",
    "\n",
    "(2) 有沒有Pooling layer, 對於參數量的差異\n",
    "\n",
    "注意: input_shape 請勿修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "#導入相關模組\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "#確認keras 版本\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 28, 28, 32)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 28, 28, 10)        330       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 10)        0         \n",
      "=================================================================\n",
      "Total params: 394\n",
      "Trainable params: 394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26, 26, 10)        330       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 10)        0         \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"(1)嘗試比對 Dense 與 layers.Conv2D 架構 NN 的差異\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "model = Sequential([\n",
    "    Dense(xxx),\n",
    "    Activation(xxx),\n",
    "    Dense(xxx),\n",
    "    Activation(xxx),\n",
    "])\n",
    "'''\n",
    "\n",
    "\"\"\" 1. Dense \"\"\"\n",
    "#建立一個序列模型\n",
    "model_11 = Sequential([\n",
    "    #\"\"\"====================================================================\"\"\"\n",
    "    Dense(32, input_shape=(28, 28, 1)), # Notice Here ! input_shape=(784,) ! 若寫 input_shape=(28,28,1) 得到的答案不對喔！\n",
    "    #\"\"\"====================================================================\"\"\"\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "#輸出模型的堆疊\n",
    "model_11.summary()\n",
    "\n",
    "\n",
    "\"\"\" 2. layers.Conv2D \"\"\"\n",
    "model_12 = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)), # Notice Here ! 但這裡就是這樣寫了！ input_shape=(28,28,1)\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])\n",
    "#輸出模型的堆疊\n",
    "model_12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 29,430\n",
      "Trainable params: 29,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 26, 26, 100)       3300      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 26, 26, 100)       0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 26, 26, 10)        1010      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 26, 26, 10)        0         \n",
      "=================================================================\n",
      "Total params: 4,630\n",
      "Trainable params: 4,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 25)        7225      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               1440100   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,448,655\n",
      "Trainable params: 1,448,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "======================================================================================================\n",
    "\n",
    "參考解答 ANS 後修正一版\n",
    "\n",
    "======================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" 1. Dense \"\"\"\n",
    "\n",
    "#建立一個序列模型\n",
    "model_11_inputShape = Sequential([\n",
    "    Dense(32, input_shape=(784,)), # Notice Here ! input_shape=(784,) ! 若寫 input_shape=(28,28,1) 得到的答案不對喔！\n",
    "    Dense(100), # Notice Here\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "#輸出模型的堆疊\n",
    "model_11_inputShape.summary()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2. layers.Conv2D \"\"\"\n",
    "model_12 = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)), # Notice Here ! 但這裡就是這樣寫了！ input_shape=(28,28,1)\n",
    "    Dense(100),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])\n",
    "#輸出模型的堆疊\n",
    "model_12.summary()\n",
    "\n",
    "\n",
    "model_12_2 = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)), # Notice Here ! 但這裡就是這樣寫了！ input_shape=(28,28,1)\n",
    "    layers.Conv2D(25, (3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(100),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])\n",
    "#輸出模型的堆疊\n",
    "model_12_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layers.Conv2D 模型, 用作比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 25)        7225      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               1440100   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,448,655\n",
      "Trainable params: 1,448,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"(2) 有沒有Pooling layer, 對於參數量的差異\"\"\"\n",
    "\n",
    "'''\n",
    "#建立一個序列模型\n",
    "model = models.Sequential()\n",
    "#建立兩個卷績層, 32 個內核, 內核大小 3x3, \n",
    "#輸入影像大小 28x28x1\n",
    "\n",
    "#建立一個全連接層\n",
    "model.add(Dense(units=100))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#建立一個輸出層, 並採用softmax\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "'''\n",
    "\n",
    "\n",
    "#建立一個序列模型\n",
    "model_2 = models.Sequential()\n",
    "\n",
    "#建立一個卷績層, 32 個內核, 內核大小 3x3, \n",
    "#輸入影像大小 28x28x1\n",
    "model_2.add(layers.Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "# #新增一池化層, 採用maxpooling\n",
    "# model_2.add(MaxPooling2D(2,2))\n",
    "\n",
    "#建立第二個卷績層, 池化層, \n",
    "#請注意, 不需要再輸入 input_shape\n",
    "model_2.add(layers.Conv2D(25, (3, 3)))\n",
    "# model_2.add(MaxPooling2D(2,2))\n",
    "\n",
    "#新增平坦層\n",
    "model_2.add(Flatten())\n",
    "\n",
    "#建立一個全連接層\n",
    "model_2.add(Dense(units=100))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "#建立一個輸出層, 並採用softmax\n",
    "model_2.add(Dense(units=10))\n",
    "model_2.add(Activation('softmax'))\n",
    "\n",
    "#輸出模型的堆疊\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.359145527369826"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1448655 / 71155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有 Pooling layer 的參數數量 是有 Pooling layer 的 20.359145527369826 倍\n"
     ]
    }
   ],
   "source": [
    "print(\"沒有 Pooling layer 的參數數量 是有 Pooling layer 的 %s 倍\" % (model_2.count_params() / model.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考資料\n",
    "\n",
    "參考連結：http://matlabtricks.com/post-5/3x3-convolution-kernels-with-online-demo#demo\n",
    "\n",
    "\n",
    "\n",
    "### 演示應用程序\n",
    "\n",
    "該程序演示了在經典圖像處理源圖像上使用3x3卷積內核。請點擊標籤加載應用程序。他應該在每個現代瀏覽器中運行，包括IE9+。\n",
    "\n",
    "![img1](https://ai100-fileentity.cupoy.com/2nd/homework/D93/1564377846048/large)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 延伸閱讀: 卷積內核幾個應用範例的效果\n",
    "\n",
    "![img2](https://ai100-fileentity.cupoy.com/2nd/homework/D93/1564377778504/large)\n",
    "\n",
    "\n",
    "### CNN 工作模型\n",
    "\n",
    "![img3](https://ai100-fileentity.cupoy.com/2nd/homework/D93/1564377818729/large)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kdnuggets.com/2017/11/understanding-deep-convolutional-neural-networks-tensorflow-keras.html/2\n",
    "\n",
    "\n",
    "![img11](https://www.kdnuggets.com/wp-content/uploads/dx.png)\n",
    "\n",
    "\n",
    "> \n",
    "    kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
    "    dy = show_differences(kernel)\n",
    "> ![img12-math](https://www.kdnuggets.com/wp-content/uploads/formula4.png)\n",
    "> ![img12](https://www.kdnuggets.com/wp-content/uploads/dy.png)\n",
    "\n",
    "\n",
    "![img13](https://www.kdnuggets.com/wp-content/uploads/features.png)\n",
    "\n",
    "\n",
    "![img14](https://www.kdnuggets.com/wp-content/uploads/relu.png)\n",
    "\n",
    "\n",
    "![img15](https://www.kdnuggets.com/wp-content/uploads/relu_test.png)\n",
    "\n",
    "\n",
    "![img16](https://www.kdnuggets.com/wp-content/uploads/max_pooling.png)\n",
    "\n",
    "\n",
    "> 卷積和池化層，其最主要的目的分別是提取特徵及減少圖像參數，然後將特徵資訊丟到 Full connected layer 來進行分類，其神經元只與上一層 kernel 的像素連結，⽽且各連結的權重在同層中是相同且共享的\n",
    "> ![img17](https://www.kdnuggets.com/wp-content/uploads/convnet-e1511970270496.png)\n",
    "\n",
    "\n",
    "![img18](https://www.kdnuggets.com/wp-content/uploads/lenet5-e1511970372498.png)\n",
    "\n",
    "\n",
    "Below a popular CNN that won the 2012 ImageNet competition (AlexNet).\n",
    "![img19](https://www.kdnuggets.com/wp-content/uploads/alexnet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jeremyjordan.me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
