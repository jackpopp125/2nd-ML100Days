{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [教學重點]\n",
    "\n",
    "學習使用 sklearn 中的 linear regression 模型，並理解各項參數的意義\n",
    "\n",
    "## [範例重點]\n",
    "\n",
    "觀察丟進模型訓練的資料格式，輸入 linear regression 與 Logistic regression 的資料有甚麼不同?\n",
    "\n",
    "\n",
    "## import 需要的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990842, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06832974, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286377, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04687948,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452837, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00421986,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - Age\\n      - Sex\\n      - Body mass index\\n      - Average blood pressure\\n      - S1\\n      - S2\\n      - S3\\n      - S4\\n      - S5\\n      - S6\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': '/Users/johnsonhuang/anaconda3/lib/python3.6/site-packages/sklearn/datasets/data/diabetes_data.csv.gz',\n",
       " 'target_filename': '/Users/johnsonhuang/anaconda3/lib/python3.6/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990842, -0.01764613]],\n",
       "\n",
       "       [[-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06832974, -0.09220405]],\n",
       "\n",
       "       [[ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286377, -0.02593034]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04687948,  0.01549073]],\n",
       "\n",
       "       [[-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452837, -0.02593034]],\n",
       "\n",
       "       [[-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00421986,  0.00306441]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.data[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.newaxis 在使用和功能上等價於 None\n",
    "\n",
    "### 1. np.newaxis 的應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.newaxis == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06169621],\n",
       "       [-0.05147406],\n",
       "       [ 0.04445121],\n",
       "       [-0.01159501],\n",
       "       [-0.03638469],\n",
       "       [-0.04069594],\n",
       "       [-0.04716281],\n",
       "       [-0.00189471],\n",
       "       [ 0.06169621],\n",
       "       [ 0.03906215],\n",
       "       [-0.08380842],\n",
       "       [ 0.01750591],\n",
       "       [-0.02884001],\n",
       "       [-0.00189471],\n",
       "       [-0.02560657],\n",
       "       [-0.01806189],\n",
       "       [ 0.04229559],\n",
       "       [ 0.01211685],\n",
       "       [-0.0105172 ],\n",
       "       [-0.01806189],\n",
       "       [-0.05686312],\n",
       "       [-0.02237314],\n",
       "       [-0.00405033],\n",
       "       [ 0.06061839],\n",
       "       [ 0.03582872],\n",
       "       [-0.01267283],\n",
       "       [-0.07734155],\n",
       "       [ 0.05954058],\n",
       "       [-0.02129532],\n",
       "       [-0.00620595],\n",
       "       [ 0.04445121],\n",
       "       [-0.06548562],\n",
       "       [ 0.12528712],\n",
       "       [-0.05039625],\n",
       "       [-0.06332999],\n",
       "       [-0.03099563],\n",
       "       [ 0.02289497],\n",
       "       [ 0.01103904],\n",
       "       [ 0.07139652],\n",
       "       [ 0.01427248],\n",
       "       [-0.00836158],\n",
       "       [-0.06764124],\n",
       "       [-0.0105172 ],\n",
       "       [-0.02345095],\n",
       "       [ 0.06816308],\n",
       "       [-0.03530688],\n",
       "       [-0.01159501],\n",
       "       [-0.0730303 ],\n",
       "       [-0.04177375],\n",
       "       [ 0.01427248],\n",
       "       [-0.00728377],\n",
       "       [ 0.0164281 ],\n",
       "       [-0.00943939],\n",
       "       [-0.01590626],\n",
       "       [ 0.0250506 ],\n",
       "       [-0.04931844],\n",
       "       [ 0.04121778],\n",
       "       [-0.06332999],\n",
       "       [-0.06440781],\n",
       "       [-0.02560657],\n",
       "       [-0.00405033],\n",
       "       [ 0.00457217],\n",
       "       [-0.00728377],\n",
       "       [-0.0374625 ],\n",
       "       [-0.02560657],\n",
       "       [-0.02452876],\n",
       "       [-0.01806189],\n",
       "       [-0.01482845],\n",
       "       [-0.02991782],\n",
       "       [-0.046085  ],\n",
       "       [-0.06979687],\n",
       "       [ 0.03367309],\n",
       "       [-0.00405033],\n",
       "       [-0.02021751],\n",
       "       [ 0.00241654],\n",
       "       [-0.03099563],\n",
       "       [ 0.02828403],\n",
       "       [-0.03638469],\n",
       "       [-0.05794093],\n",
       "       [-0.0374625 ],\n",
       "       [ 0.01211685],\n",
       "       [-0.02237314],\n",
       "       [-0.03530688],\n",
       "       [ 0.00996123],\n",
       "       [-0.03961813],\n",
       "       [ 0.07139652],\n",
       "       [-0.07518593],\n",
       "       [-0.00620595],\n",
       "       [-0.04069594],\n",
       "       [-0.04824063],\n",
       "       [-0.02560657],\n",
       "       [ 0.0519959 ],\n",
       "       [ 0.00457217],\n",
       "       [-0.06440781],\n",
       "       [-0.01698407],\n",
       "       [-0.05794093],\n",
       "       [ 0.00996123],\n",
       "       [ 0.08864151],\n",
       "       [-0.00512814],\n",
       "       [-0.06440781],\n",
       "       [ 0.01750591],\n",
       "       [-0.04500719],\n",
       "       [ 0.02828403],\n",
       "       [ 0.04121778],\n",
       "       [ 0.06492964],\n",
       "       [-0.03207344],\n",
       "       [-0.07626374],\n",
       "       [ 0.04984027],\n",
       "       [ 0.04552903],\n",
       "       [-0.00943939],\n",
       "       [-0.03207344],\n",
       "       [ 0.00457217],\n",
       "       [ 0.02073935],\n",
       "       [ 0.01427248],\n",
       "       [ 0.11019775],\n",
       "       [ 0.00133873],\n",
       "       [ 0.05846277],\n",
       "       [-0.02129532],\n",
       "       [-0.0105172 ],\n",
       "       [-0.04716281],\n",
       "       [ 0.00457217],\n",
       "       [ 0.01750591],\n",
       "       [ 0.08109682],\n",
       "       [ 0.0347509 ],\n",
       "       [ 0.02397278],\n",
       "       [-0.00836158],\n",
       "       [-0.06117437],\n",
       "       [-0.00189471],\n",
       "       [-0.06225218],\n",
       "       [ 0.0164281 ],\n",
       "       [ 0.09618619],\n",
       "       [-0.06979687],\n",
       "       [-0.02129532],\n",
       "       [-0.05362969],\n",
       "       [ 0.0433734 ],\n",
       "       [ 0.05630715],\n",
       "       [-0.0816528 ],\n",
       "       [ 0.04984027],\n",
       "       [ 0.11127556],\n",
       "       [ 0.06169621],\n",
       "       [ 0.01427248],\n",
       "       [ 0.04768465],\n",
       "       [ 0.01211685],\n",
       "       [ 0.00564998],\n",
       "       [ 0.04660684],\n",
       "       [ 0.12852056],\n",
       "       [ 0.05954058],\n",
       "       [ 0.09295276],\n",
       "       [ 0.01535029],\n",
       "       [-0.00512814],\n",
       "       [ 0.0703187 ],\n",
       "       [-0.00405033],\n",
       "       [-0.00081689],\n",
       "       [-0.04392938],\n",
       "       [ 0.02073935],\n",
       "       [ 0.06061839],\n",
       "       [-0.0105172 ],\n",
       "       [-0.03315126],\n",
       "       [-0.06548562],\n",
       "       [ 0.0433734 ],\n",
       "       [-0.06225218],\n",
       "       [ 0.06385183],\n",
       "       [ 0.03043966],\n",
       "       [ 0.07247433],\n",
       "       [-0.0191397 ],\n",
       "       [-0.06656343],\n",
       "       [-0.06009656],\n",
       "       [ 0.06924089],\n",
       "       [ 0.05954058],\n",
       "       [-0.02668438],\n",
       "       [-0.02021751],\n",
       "       [-0.046085  ],\n",
       "       [ 0.07139652],\n",
       "       [-0.07949718],\n",
       "       [ 0.00996123],\n",
       "       [-0.03854032],\n",
       "       [ 0.01966154],\n",
       "       [ 0.02720622],\n",
       "       [-0.00836158],\n",
       "       [-0.01590626],\n",
       "       [ 0.00457217],\n",
       "       [-0.04285156],\n",
       "       [ 0.00564998],\n",
       "       [-0.03530688],\n",
       "       [ 0.02397278],\n",
       "       [-0.01806189],\n",
       "       [ 0.04229559],\n",
       "       [-0.0547075 ],\n",
       "       [-0.00297252],\n",
       "       [-0.06656343],\n",
       "       [-0.01267283],\n",
       "       [-0.04177375],\n",
       "       [-0.03099563],\n",
       "       [-0.00512814],\n",
       "       [-0.05901875],\n",
       "       [ 0.0250506 ],\n",
       "       [-0.046085  ],\n",
       "       [ 0.00349435],\n",
       "       [ 0.05415152],\n",
       "       [-0.04500719],\n",
       "       [-0.05794093],\n",
       "       [-0.05578531],\n",
       "       [ 0.00133873],\n",
       "       [ 0.03043966],\n",
       "       [ 0.00672779],\n",
       "       [ 0.04660684],\n",
       "       [ 0.02612841],\n",
       "       [ 0.04552903],\n",
       "       [ 0.04013997],\n",
       "       [-0.01806189],\n",
       "       [ 0.01427248],\n",
       "       [ 0.03690653],\n",
       "       [ 0.00349435],\n",
       "       [-0.07087468],\n",
       "       [-0.03315126],\n",
       "       [ 0.09403057],\n",
       "       [ 0.03582872],\n",
       "       [ 0.03151747],\n",
       "       [-0.06548562],\n",
       "       [-0.04177375],\n",
       "       [-0.03961813],\n",
       "       [-0.03854032],\n",
       "       [-0.02560657],\n",
       "       [-0.02345095],\n",
       "       [-0.06656343],\n",
       "       [ 0.03259528],\n",
       "       [-0.046085  ],\n",
       "       [-0.02991782],\n",
       "       [-0.01267283],\n",
       "       [-0.01590626],\n",
       "       [ 0.07139652],\n",
       "       [-0.03099563],\n",
       "       [ 0.00026092],\n",
       "       [ 0.03690653],\n",
       "       [ 0.03906215],\n",
       "       [-0.01482845],\n",
       "       [ 0.00672779],\n",
       "       [-0.06871905],\n",
       "       [-0.00943939],\n",
       "       [ 0.01966154],\n",
       "       [ 0.07462995],\n",
       "       [-0.00836158],\n",
       "       [-0.02345095],\n",
       "       [-0.046085  ],\n",
       "       [ 0.05415152],\n",
       "       [-0.03530688],\n",
       "       [-0.03207344],\n",
       "       [-0.0816528 ],\n",
       "       [ 0.04768465],\n",
       "       [ 0.06061839],\n",
       "       [ 0.05630715],\n",
       "       [ 0.09834182],\n",
       "       [ 0.05954058],\n",
       "       [ 0.03367309],\n",
       "       [ 0.05630715],\n",
       "       [-0.06548562],\n",
       "       [ 0.16085492],\n",
       "       [-0.05578531],\n",
       "       [-0.02452876],\n",
       "       [-0.03638469],\n",
       "       [-0.00836158],\n",
       "       [-0.04177375],\n",
       "       [ 0.12744274],\n",
       "       [-0.07734155],\n",
       "       [ 0.02828403],\n",
       "       [-0.02560657],\n",
       "       [-0.06225218],\n",
       "       [-0.00081689],\n",
       "       [ 0.08864151],\n",
       "       [-0.03207344],\n",
       "       [ 0.03043966],\n",
       "       [ 0.00888341],\n",
       "       [ 0.00672779],\n",
       "       [-0.02021751],\n",
       "       [-0.02452876],\n",
       "       [-0.01159501],\n",
       "       [ 0.02612841],\n",
       "       [-0.05901875],\n",
       "       [-0.03638469],\n",
       "       [-0.02452876],\n",
       "       [ 0.01858372],\n",
       "       [-0.0902753 ],\n",
       "       [-0.00512814],\n",
       "       [-0.05255187],\n",
       "       [-0.02237314],\n",
       "       [-0.02021751],\n",
       "       [-0.0547075 ],\n",
       "       [-0.00620595],\n",
       "       [-0.01698407],\n",
       "       [ 0.05522933],\n",
       "       [ 0.07678558],\n",
       "       [ 0.01858372],\n",
       "       [-0.02237314],\n",
       "       [ 0.09295276],\n",
       "       [-0.03099563],\n",
       "       [ 0.03906215],\n",
       "       [-0.06117437],\n",
       "       [-0.00836158],\n",
       "       [-0.0374625 ],\n",
       "       [-0.01375064],\n",
       "       [ 0.07355214],\n",
       "       [-0.02452876],\n",
       "       [ 0.03367309],\n",
       "       [ 0.0347509 ],\n",
       "       [-0.03854032],\n",
       "       [-0.03961813],\n",
       "       [-0.00189471],\n",
       "       [-0.03099563],\n",
       "       [-0.046085  ],\n",
       "       [ 0.00133873],\n",
       "       [ 0.06492964],\n",
       "       [ 0.04013997],\n",
       "       [-0.02345095],\n",
       "       [ 0.05307371],\n",
       "       [ 0.04013997],\n",
       "       [-0.02021751],\n",
       "       [ 0.01427248],\n",
       "       [-0.03422907],\n",
       "       [ 0.00672779],\n",
       "       [ 0.00457217],\n",
       "       [ 0.03043966],\n",
       "       [ 0.0519959 ],\n",
       "       [ 0.06169621],\n",
       "       [-0.00728377],\n",
       "       [ 0.00564998],\n",
       "       [ 0.05415152],\n",
       "       [-0.00836158],\n",
       "       [ 0.114509  ],\n",
       "       [ 0.06708527],\n",
       "       [-0.05578531],\n",
       "       [ 0.03043966],\n",
       "       [-0.02560657],\n",
       "       [ 0.10480869],\n",
       "       [-0.00620595],\n",
       "       [-0.04716281],\n",
       "       [-0.04824063],\n",
       "       [ 0.08540807],\n",
       "       [-0.01267283],\n",
       "       [-0.03315126],\n",
       "       [-0.00728377],\n",
       "       [-0.01375064],\n",
       "       [ 0.05954058],\n",
       "       [ 0.02181716],\n",
       "       [ 0.01858372],\n",
       "       [-0.01159501],\n",
       "       [-0.00297252],\n",
       "       [ 0.01750591],\n",
       "       [-0.02991782],\n",
       "       [-0.02021751],\n",
       "       [-0.05794093],\n",
       "       [ 0.06061839],\n",
       "       [-0.04069594],\n",
       "       [-0.07195249],\n",
       "       [-0.05578531],\n",
       "       [ 0.04552903],\n",
       "       [-0.00943939],\n",
       "       [-0.03315126],\n",
       "       [ 0.04984027],\n",
       "       [-0.08488624],\n",
       "       [ 0.00564998],\n",
       "       [ 0.02073935],\n",
       "       [-0.00728377],\n",
       "       [ 0.10480869],\n",
       "       [-0.02452876],\n",
       "       [-0.00620595],\n",
       "       [-0.03854032],\n",
       "       [ 0.13714305],\n",
       "       [ 0.17055523],\n",
       "       [ 0.00241654],\n",
       "       [ 0.03798434],\n",
       "       [-0.05794093],\n",
       "       [-0.00943939],\n",
       "       [-0.02345095],\n",
       "       [-0.0105172 ],\n",
       "       [-0.03422907],\n",
       "       [-0.00297252],\n",
       "       [ 0.06816308],\n",
       "       [ 0.00996123],\n",
       "       [ 0.00241654],\n",
       "       [-0.03854032],\n",
       "       [ 0.02612841],\n",
       "       [-0.08919748],\n",
       "       [ 0.06061839],\n",
       "       [-0.02884001],\n",
       "       [-0.02991782],\n",
       "       [-0.0191397 ],\n",
       "       [-0.04069594],\n",
       "       [ 0.01535029],\n",
       "       [-0.02452876],\n",
       "       [ 0.00133873],\n",
       "       [ 0.06924089],\n",
       "       [-0.06979687],\n",
       "       [-0.02991782],\n",
       "       [-0.046085  ],\n",
       "       [ 0.01858372],\n",
       "       [ 0.00133873],\n",
       "       [-0.03099563],\n",
       "       [-0.00405033],\n",
       "       [ 0.01535029],\n",
       "       [ 0.02289497],\n",
       "       [ 0.04552903],\n",
       "       [-0.04500719],\n",
       "       [-0.03315126],\n",
       "       [ 0.097264  ],\n",
       "       [ 0.05415152],\n",
       "       [ 0.12313149],\n",
       "       [-0.08057499],\n",
       "       [ 0.09295276],\n",
       "       [-0.05039625],\n",
       "       [-0.01159501],\n",
       "       [-0.0277622 ],\n",
       "       [ 0.05846277],\n",
       "       [ 0.08540807],\n",
       "       [-0.00081689],\n",
       "       [ 0.00672779],\n",
       "       [ 0.00888341],\n",
       "       [ 0.08001901],\n",
       "       [ 0.07139652],\n",
       "       [-0.02452876],\n",
       "       [-0.0547075 ],\n",
       "       [-0.03638469],\n",
       "       [ 0.0164281 ],\n",
       "       [ 0.07786339],\n",
       "       [-0.03961813],\n",
       "       [ 0.01103904],\n",
       "       [-0.04069594],\n",
       "       [-0.03422907],\n",
       "       [ 0.00564998],\n",
       "       [ 0.08864151],\n",
       "       [-0.03315126],\n",
       "       [-0.05686312],\n",
       "       [-0.03099563],\n",
       "       [ 0.05522933],\n",
       "       [-0.06009656],\n",
       "       [ 0.00133873],\n",
       "       [-0.02345095],\n",
       "       [-0.07410811],\n",
       "       [ 0.01966154],\n",
       "       [-0.01590626],\n",
       "       [-0.01590626],\n",
       "       [ 0.03906215],\n",
       "       [-0.0730303 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 為方便視覺化，我們只使用資料集中的 1 個 feature (column)\n",
    "X = diabetes.data[:, np.newaxis, 2] #對照上面之後發現，X就是0,1,2 column2的那欄(那個feature)啦\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [利用numpy的newaxis轉變矩陣的形狀](http://ben-do.github.io/2016/09/15/change-shape-of-matrix-by-numpy/)\n",
    "\n",
    "有一個一維陣列x1，我分別想要把它變成一個3*1的矩陣x2，以及1*3的矩陣x3，作法如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x1 is  (3,)\n",
      "[10. 20. 30.] \n",
      "\n",
      "shape of x2 is  (3, 1)\n",
      "[[10.]\n",
      " [20.]\n",
      " [30.]] \n",
      "\n",
      "shape of x3 is  (1, 3)\n",
      "[[10. 20. 30.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([10, 20, 30], float)\n",
    "print(\"shape of x1 is \", x1.shape)\n",
    "print(x1, \"\\n\")\n",
    "\n",
    "x2 = x1[:, np.newaxis]\n",
    "print(\"shape of x2 is \", x2.shape)\n",
    "print(x2, \"\\n\")\n",
    "\n",
    "x3 = x1[np.newaxis, :]\n",
    "print(\"shape of x3 is \", x3.shape)\n",
    "print(x3, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (442, 1)\n"
     ]
    }
   ],
   "source": [
    "# 讀取糖尿病資料集\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# 為方便視覺化，我們只使用資料集中的 1 個 feature (column)\n",
    "X = diabetes.data[:, np.newaxis, 2]\n",
    "print(\"Data shape: \", X.shape) # 可以看見有 442 筆資料與我們取出的其中一個 feature\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, diabetes.target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [934.05431907]\n",
      "Mean squared error: 2569.69\n"
     ]
    }
   ],
   "source": [
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: ', regr.coef_)\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畫出回歸模型與實際資料的分佈\n",
    "plt.scatter(x_test, y_test, color = 'dodgerblue')\n",
    "plt.plot(x_test, y_pred, color = 'red', linewidth = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# 訓練模型\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "\n",
    "了解其他資料集的使用方法，如何將資料正確地送進模型訓練\n",
    "\n",
    "## 練習時間\n",
    "\n",
    "試著使用 sklearn datasets 的其他資料集 (wine, boston, ...)，來訓練自己的線性迴歸模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "boston = datasets.load_boston()\n",
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HINT: 注意 label 的型態，確定資料集的目標是分類還是回歸，再使用正確的模型訓練！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wine.target[0:5]) # logistic reg\n",
    "display(boston.target[0:5]) # linear reg\n",
    "display(breast_cancer.target[0:5]) # logistic reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target y : [24.  21.6 34.7 33.4 36.2] \n",
      "\n",
      "shape:\n",
      " (506, 13)\n",
      "\n",
      "feature name:\n",
      " ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "\n",
      " c.v. score : 0.6796744375539973\n",
      "\n",
      "Coefficients: [-1.39098133e-01  3.97316638e-02  1.56281579e-02  2.23420723e+00\n",
      " -1.73650287e+01  3.81367677e+00  4.13297396e-06 -1.32562522e+00\n",
      "  3.00934394e-01 -1.04274363e-02 -9.69146963e-01  8.59336770e-03\n",
      " -5.28261221e-01] \n",
      "\n",
      "MSE: 26.57\n"
     ]
    }
   ],
   "source": [
    "# 讀取 boston 資料集 - linear reg\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "print('target y : %s \\n' % boston.target[0:5])\n",
    "print('shape:\\n', boston.data.shape)\n",
    "print('\\nfeature name:\\n', boston.feature_names)\n",
    "\n",
    "\n",
    "# # 為方便視覺化，我們只使用資料集中的 1 個 feature (column)\n",
    "# X = boston.data[:, np.newaxis, 2]\n",
    "# print(\"Data shape: \", X.shape) # 我們取出的其中一個 feature\n",
    "\n",
    "# 上述範例是為了視覺化方便只取1個feature，這次用所有feature\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# train test split - 切分訓練集/測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "\n",
    "# model - 建立一個線性回歸模型\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# fit (train model) - 將訓練資料丟進去模型訓練\n",
    "reg.fit(X_train, y_train)\n",
    "# cross validation\n",
    "print(f'\\n c.v. score : {cross_val_score(reg, X_train, y_train, cv=5).mean()}\\n')\n",
    "\n",
    "# predict - 將測試資料丟進模型得到預測結果\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "\n",
    "# 可以看回歸模型的參數值\n",
    "print('Coefficients: %s \\n'% reg.coef_)\n",
    "\n",
    "# evaluation - 預測值與實際值的差距，使用 MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "\n",
    "\n",
    "\n",
    "# # 畫出回歸模型與實際資料的分佈\n",
    "# plt.scatter(X_test, y_test, color = 'dodgerblue')\n",
    "# plt.plot(X_test, y_pred, color = 'red', linewidth = 3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target y : [0 0 0 0 0] \n",
      "\n",
      "shape:\n",
      " (178, 13)\n",
      "\n",
      "feature name:\n",
      " ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "\n",
      "target names:\n",
      " ['class_0' 'class_1' 'class_2']\n",
      "\n",
      " c.v. score : 0.9682274247491639\n",
      "\n",
      "Accuracy:  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# 讀取 wine 資料集 - logistic reg\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "print('target y : %s \\n' % wine.target[0:5])\n",
    "print('shape:\\n', wine.data.shape)\n",
    "print('\\nfeature name:\\n', wine.feature_names)\n",
    "print('\\ntarget names:\\n', wine.target_names)\n",
    "\n",
    "# # 為方便視覺化，我們只使用資料集中的 1 個 feature (column)\n",
    "# X = wine.data[:, np.newaxis, 2]\n",
    "# print(\"Data shape: \", X.shape) # 我們取出的其中一個 feature\n",
    "\n",
    "# 上述範例是為了視覺化方便只取1個feature，這次用所有feature\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# train test split - 切分訓練集/測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "\n",
    "# model - 建立一個線性回歸模型\n",
    "logistic_reg = linear_model.LogisticRegression() # C = 0.1, 0.01, 0.0001\n",
    "\n",
    "# fit (train model) - 將訓練資料丟進去模型訓練\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "# cross validation\n",
    "print(f'\\n c.v. score : {cross_val_score(logistic_reg, X_train, y_train, cv=5).mean()}\\n')\n",
    "\n",
    "# predict - 將測試資料丟進模型得到預測結果\n",
    "y_pred = logistic_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# evaluation - 預測值與實際值的差距，使用 Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "\n",
    "\n",
    "# # 畫出回歸模型與實際資料的分佈\n",
    "# plt.scatter(X_test, y_test, color = 'dodgerblue')\n",
    "# plt.plot(X_test, y_pred, color = 'red', linewidth = 3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target y : [0 0 0 0 0] \n",
      "\n",
      "shape:\n",
      " (569, 30)\n",
      "\n",
      "feature name:\n",
      " ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "target names:\n",
      " ['malignant' 'benign']\n",
      "\n",
      " c.v. score : 0.9498076923076922\n",
      "\n",
      "Accuracy:  0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# 讀取 breast_cancer 資料集 - logistic reg\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "\n",
    "print('target y : %s \\n' % breast_cancer.target[0:5])\n",
    "print('shape:\\n', breast_cancer.data.shape)\n",
    "print('\\nfeature name:\\n', breast_cancer.feature_names)\n",
    "print('\\ntarget names:\\n', breast_cancer.target_names)\n",
    "\n",
    "# # 為方便視覺化，我們只使用資料集中的 1 個 feature (column)\n",
    "# X = breast_cancer.data[:, np.newaxis, 2]\n",
    "# print(\"Data shape: \", X.shape) # 我們取出的其中一個 feature\n",
    "\n",
    "# 上述範例是為了視覺化方便只取1個feature，這次用所有feature\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# train test split - 切分訓練集/測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "\n",
    "# model - 建立一個線性回歸模型\n",
    "logistic_reg = linear_model.LogisticRegression() # C = 0.1, 0.01, 0.0001\n",
    "\n",
    "# fit (train model) - 將訓練資料丟進去模型訓練\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "# cross validation\n",
    "print(f'\\n c.v. score : {cross_val_score(logistic_reg, X_train, y_train, cv=5).mean()}\\n')\n",
    "\n",
    "# predict - 將測試資料丟進模型得到預測結果\n",
    "y_pred = logistic_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# evaluation - 預測值與實際值的差距，使用 Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "\n",
    "\n",
    "# # 畫出回歸模型與實際資料的分佈\n",
    "# plt.scatter(X_test, y_test, color = 'dodgerblue')\n",
    "# plt.plot(X_test, y_pred, color = 'red', linewidth = 3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [超多 Linear Regression / Logistic Regression 的 examples](https://github.com/trekhleb/homemade-machine-learning)\n",
    "\n",
    "![img](https://github.com/trekhleb/homemade-machine-learning/blob/master/images/machine-learning-map.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [深入了解 multinomial Logistic Regression 的原理](http://dataaspirant.com/2017/05/15/implement-multinomial-logistic-regression-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
