{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(87)\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新聞標題 (文字應用的NN)\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Embedding  # Embedding 層將輸入序列編碼為一個稠密向量的序列\n",
    "from keras.layers import LSTM       # LSTM 層把向量序列轉換成單個向量，它包含整個序列的上下文信息\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定一些參數\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "# 資料準備 / 取得資料，並分成 Training 與 Test set\n",
    "(x_img_train,y_label_train), (x_img_test, y_label_test) = cifar10.load_data()\n",
    "\n",
    "# 確認資料維度\n",
    "print(\"train data:\",'images:', x_img_train.shape, \" labels:\", y_label_train.shape) \n",
    "print(\"test  data:\",'images:', x_img_test.shape , \" labels:\", y_label_test.shape) \n",
    "\n",
    "\n",
    "# 資料(影像)正規化 (Image normalization)，並設定 data array 為浮點數\n",
    "x_img_train_normalize = x_img_train.astype('float32') / 255.0\n",
    "x_img_test_normalize = x_img_test.astype('float32') / 255.0\n",
    "\n",
    "# 轉換 label 為 OneHot Encoding (只要是做分類問題的時候，都要對 label 做 one-hot encoding喔！) Convert class vectors to binary class matrices.\n",
    "# 針對 Label 做 ONE HOT Encoding, 並查看維度資訊\n",
    "from keras.utils import np_utils\n",
    "y_label_train_OneHot = np_utils.to_categorical(y_label_train)\n",
    "y_label_test_OneHot = np_utils.to_categorical(y_label_test)\n",
    "print(y_label_test_OneHot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP (多層 Perceptron) 的優缺點\n",
    "\n",
    "MLP 優點\n",
    "\n",
    "> 建立 「非線性」 模型、 「real-time」 模型\n",
    "\n",
    "MLP 缺點\n",
    "\n",
    ">使用不同的初始權重，會讓驗證時的準確率浮動 MLP 需要調整每層神經元數、層數、迭代次數 對於特徵預處理很敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "# build model\n",
    "\"\"\"\n",
    "NN的組成\n",
    "\n",
    "1. Input Layer\n",
    "\n",
    "    Weights\n",
    "\n",
    "2. Hidden Layer\n",
    "\n",
    "    Net Input Function\n",
    "\n",
    "    Activation Function : 給神經元引入非線性因素，使得 神經網路能任意逼近任何非線性函數\n",
    "\n",
    "3. Output Layer\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"# model - 1\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"# model - 2\"\"\"\n",
    "# 宣告採用序列模型\n",
    "model = Sequential()\n",
    "\n",
    "# 卷積層1 - filters=32\n",
    "# 與池化層1\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(3,3),\n",
    "                 input_shape=(32, 32,3), \n",
    "                 activation='relu', \n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 卷積層2 - filters=64\n",
    "# 與池化層2\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu', \n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 卷積層3 - filters=128\n",
    "# 與池化層3\n",
    "model.add(Conv2D(filters=128, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu', \n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 卷積層4 - filters=256\n",
    "# 與池化層4\n",
    "model.add(Conv2D(filters=256, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu', \n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\"\"\"\n",
    "# 建立神經網路(平坦層、隱藏層、輸出層)\n",
    "\"\"\"\n",
    "\"\"\" 1. Flatten layer (Input Layer) \"\"\"\n",
    "model.add(Flatten())\n",
    "\n",
    "\"\"\" 2. Fully Connected Layer (Hidden Layer) \"\"\"\n",
    "# 建立全網路連接層\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "\"\"\" 3. Output Layer \"\"\"\n",
    "#建立輸出層\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#檢查model 的STACK\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入之前訓練的模型\n",
    "\n",
    "try:\n",
    "    model.load_weights(\"SaveModel/cifarCnnModel.h5\")\n",
    "    print(\"載入模型成功!繼續訓練模型\")\n",
    "except :    \n",
    "    print(\"載入模型失敗!開始訓練一個新模型\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model (模型編譯)\n",
    "\"\"\"\n",
    "# 模型編譯\n",
    "\n",
    "在訓練模型之前，您需要配置學習過程，的英文這通過compile方法完成的它接收三個參數：\n",
    "\n",
    "1. Optimizer\n",
    "\n",
    "優化器optimizer。它可以是現有優化器的字符串標識符，如rmsprop或adagrad，也可以是Optimizer類的實例。\n",
    "\n",
    "2. Loss\n",
    "\n",
    "損失函數的損失，模型試圖最小化的目標函數它可以是現有損失函數的字符串標識符，如。categorical_crossentropy或mse，也可以是一個目標函數\n",
    "\n",
    "3. metrics 評估指標\n",
    "\n",
    "評估標準指標。對於任何分類問題，你都希望將其設置為metrics = ['accuracy']。評估標準可以是現有的標準的字符串標識符，也可以是自定義的評估標準函數。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(train) model\n",
    "\n",
    "\n",
    "#模型訓練, \"Train_History\" 把訓練過程所得到的數值存起來\n",
    "train_history = model.fit(x_img_train_normalize, y_label_train_OneHot,\n",
    "                          validation_split=0.25,\n",
    "                          epochs=12, \n",
    "                          batch_size=128, \n",
    "                          verbose=1\n",
    "                         )         \n",
    "\n",
    "# [validation_split = 0.2] validation_split：在0和1之間浮動。用作驗證數據的訓練數據的比例。\n",
    "# 該模型將訓練數據的這一部分分開，不會對其進行訓練，並將在每個時期結束時評估該數據的損失和任何模型指標。\n",
    "# [batch_size]：整數或None。每個梯度更新的樣本數。指定，batch_size為128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畫出 train acc, validation acc，以檢視是否有 overfitting / underfitting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 定義一個繪圖函數\n",
    "def show_train_history(train_acc, test_acc):\n",
    "    plt.plot(train_history.history[train_acc])\n",
    "    plt.plot(train_history.history[test_acc])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "show_train_history('acc', 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model.evaluate(x_Test_normalize, y_Test_OneHot)\n",
    "\n",
    "scores = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "print()\n",
    "print('accuracy=',scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合 compile, fit, plot, scores\n",
    "\n",
    "def check_model(loss_function) :\n",
    "        \n",
    "    model.compile(loss = loss_function, optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    #模型訓練, \"Train_History\" 把訓練過程所得到的數值存起來\n",
    "    train_history = model.fit(x_img_train_normalize, \n",
    "                              y_label_train_OneHot,\n",
    "                              validation_split=0.25,\n",
    "                              epochs=12, \n",
    "                              batch_size=128, \n",
    "                              verbose=1\n",
    "                             )         \n",
    "\n",
    "    # [validation_split = 0.2] validation_split：在0和1之間浮動。用作驗證數據的訓練數據的比例。\n",
    "    # 該模型將訓練數據的這一部分分開，不會對其進行訓練，並將在每個時期結束時評估該數據的損失和任何模型指標。\n",
    "    # [batch_size]：整數或None。每個梯度更新的樣本數。指定，batch_size為128\n",
    "\n",
    "    # 定義一個繪圖函數\n",
    "    def show_train_history(train_history, train, validation):\n",
    "        plt.plot(train_history.history[train])\n",
    "        plt.plot(train_history.history[validation])\n",
    "        plt.title('Train History')\n",
    "        plt.ylabel(train)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "    # plot\n",
    "    show_train_history(train_history, 'acc', 'val_acc')\n",
    "    show_train_history(train_history, 'loss', 'val_loss')\n",
    "\n",
    "    # scores\n",
    "    scores = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "    print()\n",
    "    print('accuracy=',scores[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "#check_model(loss_function)\n",
    "check_model('categorical_crossentropy')\n",
    "check_model('mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
